Loading BERT embedder and feature extractor...

######################################################################
# VALIDATION SET: Combined Validation Set
# Path: /Users/jwalinshah/projects/jarvis-ai-assistant/validation_sets_multilabel.jsonl
######################################################################

Loading validation data...
Loaded 400 examples
  Extracting 915-dim features...
    Current BERT:   0%|          | 0/4 [00:00<?, ?it/s]mx.metal.set_memory_limit is deprecated and will be removed in a future version. Use mx.set_memory_limit instead.
mx.metal.set_cache_limit is deprecated and will be removed in a future version. Use mx.set_cache_limit instead.
    Current BERT:  25%|██▌       | 1/4 [00:01<00:04,  1.61s/it]    Current BERT:  50%|█████     | 2/4 [00:01<00:01,  1.34it/s]    Current BERT:  75%|███████▌  | 3/4 [00:01<00:00,  2.18it/s]                                                               [BERT] BEFORE mx.load: RSS=259.1 MB, VMS=401938.1 MB
[BERT] AFTER mx.load: RSS=259.5 MB (+0.4), VMS=401938.1 MB (+0.0)
[BERT] BEFORE model.load_weights: RSS=259.5 MB, VMS=401938.1 MB
[BERT] AFTER model.load_weights: RSS=259.8 MB (+0.3), VMS=401938.1 MB (+0.0)
[BERT] AFTER deleting weight dicts: RSS=259.8 MB, VMS=401938.1 MB
[BERT] BEFORE mx.eval: RSS=259.8 MB, VMS=401938.1 MB
[BERT] AFTER mx.eval: RSS=387.4 MB (+127.6), VMS=402069.8 MB (+131.7)
[BERT] AFTER mx.clear_cache: RSS=387.4 MB, VMS=402069.8 MB
    Context BERT:   0%|          | 0/4 [00:00<?, ?it/s]    Context BERT:  25%|██▌       | 1/4 [00:00<00:00,  4.34it/s]    Context BERT:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]    Context BERT:  75%|███████▌  | 3/4 [00:01<00:00,  2.20it/s]    Context BERT: 100%|██████████| 4/4 [00:01<00:00,  2.22it/s]                                                                   Non-BERT:   0%|          | 0/400 [00:00<?, ?it/s]    Non-BERT:   0%|          | 1/400 [00:00<01:36,  4.13it/s]    Non-BERT:  10%|▉         | 39/400 [00:00<00:02, 143.33it/s]    Non-BERT:  20%|██        | 82/400 [00:00<00:01, 241.17it/s]    Non-BERT:  31%|███       | 124/400 [00:00<00:00, 299.43it/s]    Non-BERT:  41%|████▏     | 165/400 [00:00<00:00, 333.75it/s]    Non-BERT:  51%|█████     | 203/400 [00:00<00:00, 345.15it/s]    Non-BERT:  60%|██████    | 241/400 [00:00<00:00, 355.43it/s]    Non-BERT:  71%|███████   | 283/400 [00:00<00:00, 373.33it/s]    Non-BERT:  81%|████████  | 324/400 [00:01<00:00, 382.95it/s]    Non-BERT:  91%|█████████ | 364/400 [00:01<00:00, 386.96it/s]                                                                  Feature matrix: (400, 915)

======================================================================
EVALUATING: LinearSVC (915 features, tuned)
======================================================================
Loading model from /Users/jwalinshah/projects/jarvis-ai-assistant/models/category_multilabel_hardclass.joblib...
Loading thresholds from /Users/jwalinshah/projects/jarvis-ai-assistant/models/category_multilabel_hardclass_optimal_thresholds.json...
Getting predictions...
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])

Per-class classification report:
              precision    recall  f1-score   support

 acknowledge     0.4490    0.3548    0.3964        62
     closing     0.1667    0.5000    0.2500         2
     emotion     0.7391    0.4951    0.5930       103
    question     0.8857    0.4429    0.5905        70
     request     0.4194    0.3824    0.4000        34
   statement     0.7958    0.5045    0.6175       224

   micro avg     0.6958    0.4667    0.5586       495
   macro avg     0.5759    0.4466    0.4746       495
weighted avg     0.7249    0.4667    0.5645       495
 samples avg     0.5225    0.5158    0.5052       495


Multi-label metrics:
  F1 (samples): 0.5052
  F1 (macro):   0.4746
  Hamming loss: 0.1521
  Jaccard:      0.4752

======================================================================
EVALUATING: LightGBM (915 features, tuned)
======================================================================
Loading model from /Users/jwalinshah/projects/jarvis-ai-assistant/models/category_multilabel_lightgbm_hardclass.joblib...
Loading thresholds from /Users/jwalinshah/projects/jarvis-ai-assistant/models/category_multilabel_lightgbm_hardclass_optimal_thresholds.json...
Getting predictions...
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/Users/jwalinshah/projects/jarvis-ai-assistant/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])

Per-class classification report:
              precision    recall  f1-score   support

 acknowledge     0.4898    0.3871    0.4324        62
     closing     0.0000    0.0000    0.0000         2
     emotion     0.7000    0.6117    0.6528       103
    question     0.8947    0.4857    0.6296        70
     request     0.3939    0.3824    0.3881        34
   statement     0.6534    0.9509    0.7745       224

   micro avg     0.6474    0.7010    0.6731       495
   macro avg     0.5220    0.4696    0.4796       495
weighted avg     0.6563    0.7010    0.6562       495
 samples avg     0.6971    0.7650    0.7023       495


Multi-label metrics:
  F1 (samples): 0.7023
  F1 (macro):   0.4796
  Hamming loss: 0.1404
  Jaccard:      0.6404

######################################################################
# VALIDATION SET: Validation Set 2
# Path: /Users/jwalinshah/projects/jarvis-ai-assistant/validation_set_2_labeled.jsonl
######################################################################

Loading validation data...
Traceback (most recent call last):
  File "/Users/jwalinshah/projects/jarvis-ai-assistant/scripts/evaluate_on_validation_sets.py", line 249, in <module>
    main()
    ~~~~^^
  File "/Users/jwalinshah/projects/jarvis-ai-assistant/scripts/evaluate_on_validation_sets.py", line 214, in main
    texts, labels, contexts = load_validation_set(val_path)
                              ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/Users/jwalinshah/projects/jarvis-ai-assistant/scripts/evaluate_on_validation_sets.py", line 45, in load_validation_set
    labels.append(example["labels"])
                  ~~~~~~~^^^^^^^^^^
KeyError: 'labels'
