# Validation Strategy

> **Last Updated:** 2026-02-13

This document outlines the validation strategy for JARVIS, particularly focusing on the Fact Extraction and Contact Profiling (V4) pipeline.

## V4 Fact Extraction Validation

The V4 pipeline introduces several critical components that require validation:

1.  **Turn-Based Grouping**: Ensuring messages are correctly grouped by sender and time gap.
2.  **Address Book Resolution**: Verifying that contact names and the user's identity are correctly resolved from the macOS Address Book.
3.  **NLI Verification**: Confirming that the Natural Language Inference model correctly accepts valid facts and rejects hallucinations or contradictions.
4.  **Relationship Reasoning**: Validating that the LLM produces logical justifications for relationship labels.

### Validation Datasets

*   **`data/validation_evaluation_with_context.txt`**: Contains pairs of (source_text, hypothesis_fact) with human-annotated labels (ENTAILED, CONTRADICTION, NEUTRAL). Used to evaluate the NLI model's precision.
*   **`data/validation_evaluation_semantic_context.txt`**: Focuses on subtler semantic distinctions and context dependencies.
*   **`data/fact_evaluation_report.txt`**: Automated reports generated by the evaluation pipeline, summarizing precision, recall, and F1 scores.

### Running Validation

To run the full validation suite:

```bash
python scripts/validate_facts.py
```

This script will:
1.  Load the validation datasets.
2.  Run the NLI model against the labeled pairs.
3.  Compute metrics (Accuracy, Precision, Recall).
4.  Output a report to `data/validation_results_new.txt`.

### Regression Testing

Before merging changes to the extraction logic or NLI model versions, ensure that:
*   Overall accuracy on `validation_evaluation_with_context.txt` does not drop below 0.85.
*   Latency per verification stays under 200ms (P95).

## System-Wide Validation

Refer to `docs/TESTING_GUIDELINES.md` for general unit and integration testing standards.
