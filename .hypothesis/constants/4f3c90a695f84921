# file: /Users/jwalinshah/projects/jarvis-ai-assistant/jarvis/config.py
# hypothesis_version: 6.151.5

[0.0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.85, 0.95, 0.99, 1.0, 1.2, 2.0, 3.0, 5.0, 10.0, 30.0, 60.0, 300.0, 600.0, 1440.0, 3600.0, 100, 150, 168, 200, 384, 500, 1000, 1440, 2000, 2048, 4000, 4096, 5000, 8000, 8760, 10000, '.jarvis', '08:00', '^\\d{2}:\\d{2}$', 'bge-small', 'biu-nlp/f-coref', 'chat', 'config.json', 'config_version', 'context', 'control', 'daily', 'dark', 'default_limit', 'digest', 'embedding', 'embeddings', 'embeddings.db', 'en_core_web_trf', 'faiss_index', 'generate', 'html', 'jarvis-embed.sock', 'lfm-1.2b', 'light', 'markdown', 'mlx_service_socket', 'mlx_service_url', 'model', 'model_id', 'model_path', 'quick_reply', 'qwen-0.5b', 'qwen-1.5b', 'qwen-3b', 'rate_limit', 'retrieval', 'routing', 'search', 'segmentation', 'system', 'task_queue', 'template_threshold', 'ui', 'vec_search', 'w', 'weekly']