# JARVIS Benchmark Results

**Generated**: 2026-01-26 04:20:50
**Results Directory**: `results`
**Platform**: Linux (x86_64)

## Environment Notes

This benchmark run was executed on a Linux environment without Apple Silicon hardware.
JARVIS is designed for macOS with Apple Silicon (M1/M2/M3) and uses the MLX framework
for efficient on-device inference. The benchmarks have specific hardware requirements:

| Benchmark | Requirement | Status on This Platform |
|-----------|-------------|------------------------|
| Memory Profiling (G1) | Apple Silicon + MLX | SKIPPED |
| HHEM Evaluation (G2) | Vectara model + trust_remote_code | SKIPPED |
| Latency (G3, G4) | Apple Silicon + MLX | SKIPPED |

To run these benchmarks properly, use a macOS machine with Apple Silicon and run:
```bash
./scripts/overnight_eval.sh
```

## Gate Summary

| Gate | Metric | Value | Threshold | Status |
|------|--------|-------|-----------|--------|
| G1 | Model Stack Memory | MLX not available (requires Apple Silicon macOS) | <5.5GB | SKIP |
| G2 | Mean HHEM Score | HHEM model requires trust_remote_code=True (code modification needed) | >=0.5 | SKIP |
| G3 | Warm-Start Latency (p95) | MLX not available (requires Apple Silicon macOS) | <3s | SKIP |
| G4 | Cold-Start Latency (p95) | MLX not available (requires Apple Silicon macOS) | <15s | SKIP |

**Recommendation**: Proceed with development

---

## Memory Profile (G1)

*No memory profiling results available - requires Apple Silicon with MLX.*

When run on compatible hardware, this benchmark profiles:
- **Model**: Qwen2.5-0.5B-Instruct-4bit (default)
- **Measurements**: RSS memory, Metal GPU memory, load time
- **Context lengths**: 256, 512, 1024, 2048

**Target**: Total model stack memory < 5.5GB

## Hallucination Evaluation (G2)

*No evaluation results available - requires HHEM model access.*

When run properly, this benchmark:
- Uses Vectara's HHEM (Hallucination Evaluation Model)
- Evaluates model responses against source documents
- Scores from 0 (hallucinated) to 1 (grounded)
- Tests 60 mixed grounded/hallucinated pairs

**Target**: Mean HHEM score >= 0.5

## Latency Benchmarks (G3, G4)

*No latency benchmark results available - requires Apple Silicon with MLX.*

When run on compatible hardware, this benchmark measures:

| Scenario | Description | Target |
|----------|-------------|--------|
| Cold Start | Model loaded from disk | < 15s (p95) |
| Warm Start | Model already loaded, new prompt | < 3s (p95) |
| Hot Start | Model loaded, same prompt prefix | < 3s (p95) |

---

## Running Benchmarks on Compatible Hardware

To run the full benchmark suite on Apple Silicon:

```bash
# Full evaluation (recommended overnight)
./scripts/overnight_eval.sh

# Quick mode for testing
./scripts/overnight_eval.sh --quick

# Individual benchmarks
python -m benchmarks.memory.run --output results/memory.json
python -m benchmarks.hallucination.run --output results/hhem.json
python -m benchmarks.latency.run --output results/latency.json

# Check gates
python scripts/check_gates.py results/

# Generate report
python scripts/generate_report.py --results-dir results/ --output BENCHMARKS.md
```

---

*Report generated by `scripts/generate_report.py`*
