# Multi-Agent Proposed Diffs

Generated by 5 agents reviewing the JARVIS codebase.

---

## DIFF 1: Codex - Router Optimization (Issues #1, #4)

**Changes:**
- Move context-dependent check BEFORE FAISS search to avoid wasted latency
- Add early coherence filtering to prevent quick_reply churn

```diff
--- a/jarvis/router.py
+++ b/jarvis/router.py
@@ -782,28 +782,9 @@ class ReplyRouter:
         quick_reply_threshold = thresholds["quick_reply"]
         context_threshold = thresholds["context"]
         generate_threshold = thresholds["generate"]
+        search_results = []

-        # Step 5: Search FAISS index for similar triggers
-        # Note: CachedEmbedder already has the embedding cached from precomputation
-        try:
-            search_start = time.perf_counter()
-            search_results = self.index_searcher.search_with_pairs(
-                query=incoming,
-                k=5,
-                threshold=generate_threshold,
-                prefer_recent=True,
-                embedder=cached_embedder,
-            )
-            latency_ms["faiss_search"] = (time.perf_counter() - search_start) * 1000
-        except FileNotFoundError:
-            logger.warning("FAISS index not found, falling back to generation")
-            search_results = []
-        except Exception as e:
-            logger.exception("Error searching index: %s", e)
-            search_results = []
-
-        # Step 6: Check if message is context-dependent (needs current info)
+        # Step 5: Check if message is context-dependent (needs current info)
         is_context_dependent = self._is_context_dependent(incoming)
         if is_context_dependent:
             logger.debug("Message is context-dependent, skipping quick_reply matching")
@@ -837,16 +818,46 @@ class ReplyRouter:
                 decision="generate",
             )

-        # Step 7: Route based on best similarity score
+        # Step 6: Search FAISS index for similar triggers
+        try:
+            search_start = time.perf_counter()
+            search_results = self.index_searcher.search_with_pairs(
+                query=incoming,
+                k=5,
+                threshold=generate_threshold,
+                prefer_recent=True,
+                embedder=cached_embedder,
+            )
+            latency_ms["faiss_search"] = (time.perf_counter() - search_start) * 1000
+        except FileNotFoundError:
+            logger.warning("FAISS index not found, falling back to generation")
+            search_results = []
+        except Exception as e:
+            logger.exception("Error searching index: %s", e)
+            search_results = []
+
+        # Step 7: Filter coherent results early to avoid quick_reply churn
+        coherent_results = []
+        for m in search_results:
+            coherence = score_response_coherence(
+                m.get("trigger_text", incoming),
+                m["response_text"],
+            )
+            if coherence >= COHERENCE_THRESHOLD:
+                coherent_results.append(m)
+
+        # Step 8: Route based on best similarity score
         if search_results:
             best_result = search_results[0]
             best_score = best_result["similarity"]

             # High confidence -> quick_reply response with top-K variety
-            if best_score >= quick_reply_threshold:
+            if coherent_results and coherent_results[0]["similarity"] >= quick_reply_threshold:
                 high_confidence_matches = [
-                    r for r in search_results if r["similarity"] >= quick_reply_threshold
+                    r for r in coherent_results if r["similarity"] >= quick_reply_threshold
                 ]
```

---

## DIFF 2: Claude - Intent Utilization (Issue #2)

**Changes:**
- Use IntentType.REPLY, SUMMARIZE, SEARCH to adjust routing behavior
- Different intents get different threshold adjustments
- Pass intent_strategy to _generate_response for prompt modifications

```diff
--- a/jarvis/router.py
+++ b/jarvis/router.py
@@ -778,6 +778,44 @@ class ReplyRouter:
                 decision="quick_reply",
             )

+        # Step 3b: Adjust routing behavior based on intent classification
+        intent_threshold_adjustment = 0.0
+        intent_strategy = None
+
+        if intent_result and intent_result.confidence >= 0.7:
+            if intent_result.intent == IntentType.REPLY:
+                # User wants help composing - favor generation over quick_reply
+                intent_threshold_adjustment = 0.10
+                intent_strategy = "favor_generation"
+                logger.debug("REPLY intent detected, raising quick_reply threshold")
+            elif intent_result.intent == IntentType.SUMMARIZE:
+                # User wants summarization - skip quick_reply entirely
+                intent_threshold_adjustment = 1.0
+                intent_strategy = "summarize"
+                logger.debug("SUMMARIZE intent detected, forcing generation path")
+            elif intent_result.intent == IntentType.SEARCH:
+                # User searching for info - favor example retrieval
+                intent_threshold_adjustment = 0.15
+                intent_strategy = "search_synthesis"
+                logger.debug("SEARCH intent detected, favoring example retrieval")
+
         thresholds = self._get_thresholds()
-        quick_reply_threshold = thresholds["quick_reply"]
+        quick_reply_threshold = thresholds["quick_reply"] + intent_threshold_adjustment
         context_threshold = thresholds["context"]
```

---

## DIFF 3: Kimi - Pattern Ordering & Cleanup (Issues #5, #13-16)

**Changes:**
- Reorder ACKNOWLEDGE patterns to avoid REACT_POSITIVE conflicts
- Remove unused RouteResult dataclass
- Remove unused IndexNotAvailableError exception
- Consolidate _REFERENCE_WORDS into _VAGUE_REFERENCES
- Fix redundant if thread checks

```diff
--- a/jarvis/response_classifier_v2.py
+++ b/jarvis/response_classifier_v2.py
@@ -389,6 +389,7 @@ STRUCTURAL_PATTERNS_V2: dict[ResponseTypeV2, list[tuple[str, bool]]] = {
     ResponseTypeV2.ACKNOWLEDGE: [
         (r"^(ok|okay|k|kk|okok|okk)[\s!.]*$", True),
         (r"^(got it|gotcha|gotchu)[\s!.]*$", True),
+        (r"^(oh\s+ok|ohh\s+ok)[\s!.]*$", True),
         (r"^(alright|aight|aite|ight)[\s!.]*$", True),
         (r"^(cool|nice|great|awesome)[\s!.]*$", True),
         (r"^(noted|understood|copy|roger)[\s!.]*$", True),
@@ -397,7 +398,6 @@ STRUCTURAL_PATTERNS_V2: dict[ResponseTypeV2, list[tuple[str, bool]]] = {
         (r"^(fair enough|makes sense)[\s!.]*$", True),
         (r"^(i see|ohh|ahh|ohhh)[\s!.]*$", True),
         (r"^(word|bet)[\s!.]*$", True),
-        (r"^(mhm|oh\s+ok|good|oh)[\s!.]*$", True),
     ],
```

```diff
--- a/jarvis/router.py
+++ b/jarvis/router.py
@@ -135,22 +135,14 @@ _CONTEXT_STARTER_PREFIXES = frozenset({"what time", "when ", "where ", "which "}

 # Vague reference patterns - consolidated (was duplicated in _REFERENCE_WORDS)
 _VAGUE_REFERENCES = frozenset({
     "that", "it", "the thing", "this", "those", "these",
     "what you said", "what we discussed", "the other", "the other thing",
 })
-
-# REMOVED: _REFERENCE_WORDS was duplicate of _VAGUE_REFERENCES subset
 _TIME_WORDS = frozenset({"when", "what time"})
 _LOCATION_WORDS = frozenset({"where", "location"})

-# REMOVED: IndexNotAvailableError - never raised, FileNotFoundError used instead
-# REMOVED: RouteResult dataclass - never instantiated, dicts used instead
-
@@ -530,12 +530,9 @@ class ReplyRouter:
         # If we have active thread context, likely mid-conversation
         if thread and len(thread) >= 2:
-            if thread:
-                last_thread_msg = thread[-1] if thread else ""
-                if "?" in last_thread_msg:
-                    logger.debug("Acknowledgment follows question, generating substantive response")
-                    return True
+            last_thread_msg = thread[-1]
+            if "?" in last_thread_msg:
+                logger.debug("Acknowledgment follows question, generating substantive response")
+                return True
             return True
```

---

## DIFF 4: Gemini - Retrieval Improvements (Issues #3, #6)

**Changes:**
- Increase oversampling from k*5 to k*20 for rare response types
- Add diversity filtering to skip duplicate responses

```diff
--- a/jarvis/retrieval.py
+++ b/jarvis/retrieval.py
@@ -225,7 +225,7 @@ class TypedRetriever:
         try:
             search_results = self.index_searcher.search_with_pairs(
                 query=trigger,
-                k=k * 5,  # Get extra for filtering
+                k=k * 20,  # Increased oversampling for rare types like DECLINE
                 threshold=min_similarity,
                 embedder=embedder,
             )
@@ -234,6 +234,7 @@ class TypedRetriever:
             search_results = []

         # Filter to target response type
+        seen_responses = set()  # Diversity filter
         typed_examples = []
         for result in search_results:
             pair_id = result.get("pair_id")
@@ -248,6 +249,12 @@ class TypedRetriever:
             if quality < min_quality:
                 continue

+            # Diversity check: Skip duplicate response texts
+            response_normalized = result["response_text"].strip().lower()
+            if response_normalized in seen_responses:
+                continue
+            seen_responses.add(response_normalized)
+
             typed_examples.append(
                 TypedExample(
                     trigger_text=result["trigger_text"],
```

---

## DIFF 5: OpenCode - Topic Segmentation (Issues #7, #8, #9)

**Changes:**
- Adaptive min_cluster_size based on message count
- Dynamic entity weight based on entity density
- Full entity match before token-level fallback

```diff
--- a/jarvis/topic_discovery.py
+++ b/jarvis/topic_discovery.py
@@ -100,8 +100,13 @@ class TopicClassifier:
-    def classify(self, embedding, entities=None, cosine_weight=0.7, entity_weight=0.3):
+    def classify(self, embedding, entities=None, cosine_weight=None, entity_weight=None):
+        # Dynamic weights based on entity density
+        if cosine_weight is None:
+            avg_density = np.mean([t.entity_density for t in self.topics]) if self.topics else 0
+            entity_weight = min(0.5, avg_density / 2.0) if avg_density > 0 else 0.3
+            cosine_weight = 1.0 - entity_weight

@@ -193,9 +198,15 @@ class TopicDiscovery:
     def _compute_entity_overlap(self, message_entities, topic_entities):
-        # Token-level matching
-        msg_tokens = {t.lower() for e in message_entities for t in e.split() if len(t) > 2}
-        topic_tokens = {t.lower() for e in topic_entities for t in e.split() if len(t) > 2}
-        return len(msg_tokens & topic_tokens) / max(len(msg_tokens | topic_tokens), 1)
+        # Try full entity match first
+        msg_set = {e.lower() for e in message_entities}
+        topic_set = {e.lower() for e in topic_entities}
+        full_overlap = len(msg_set & topic_set)
+        if full_overlap > 0:
+            return full_overlap / max(len(msg_set | topic_set), 1)
+        # Fallback to token-level matching
+        msg_tokens = {t.lower() for e in message_entities for t in e.split() if len(t) > 2}
+        topic_tokens = {t.lower() for e in topic_entities for t in e.split() if len(t) > 2}
+        return len(msg_tokens & topic_tokens) / max(len(msg_tokens | topic_tokens), 1)

@@ -452,7 +462,16 @@ class TopicDiscovery:
-        min_cluster_size = self.min_cluster_size
+        min_cluster_size = self._compute_adaptive_cluster_size(len(embeddings))
+
+    def _compute_adaptive_cluster_size(self, n_messages: int) -> int:
+        """Larger conversations need larger minimum clusters."""
+        if n_messages < 50:
+            return 3
+        elif n_messages < 200:
+            return 5
+        elif n_messages < 500:
+            return 8
+        else:
+            return min(15, n_messages // 50)
```

---

## Summary

| Diff | Agent | Files | Impact |
|------|-------|-------|--------|
| #1 | Codex | router.py | High - latency + correctness |
| #2 | Claude | router.py | High - routing accuracy |
| #3 | Kimi | router.py, response_classifier_v2.py | Medium - cleanup + patterns |
| #4 | Gemini | retrieval.py | Medium - rare type recall |
| #5 | OpenCode | topic_discovery.py | Medium - clustering quality |

**Recommended order:**
1. Diff #3 (cleanup) - Low risk, immediate benefit
2. Diff #4 (retrieval) - Low risk, improves rare types
3. Diff #1 (router optimization) - Medium risk, needs testing
4. Diff #5 (topic segmentation) - Medium risk, needs testing
5. Diff #2 (intent utilization) - Higher risk, new behavior
